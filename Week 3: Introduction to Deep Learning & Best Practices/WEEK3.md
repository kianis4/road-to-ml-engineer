# Week 3: Introduction to Deep Learning & Best Practices

## Goal
- Learn basic deep learning (MLP, CNN) using TensorFlow/Keras or PyTorch.
- Implement best practices: experiment tracking, good coding structure, data augmentation.
- Relate to industry applications like image classification & structured data.

## Monday: Neural Net Fundamentals
**Topics:**
- Perceptron, activation functions, forward/backprop.

**Notebook (03_deep_learning_intro.ipynb):**
- Implement a simple MLP “by hand” or at least show a small forward pass example.

## Tuesday: Framework Setup & MNIST MLP
**Topics:**
- Basic usage of TensorFlow or PyTorch.

**Notebook Tasks:**
- Build a simple MLP for MNIST classification, track accuracy & loss.
- Use TensorBoard or Weights & Biases for experiment logging.

## Wednesday: CNNs for Image Classification
**Topics:**
- Convolution, pooling, ReLU, typical CNN architecture.

**Notebook Tasks:**
- Implement a small CNN on MNIST/Fashion-MNIST or CIFAR-10.
- Compare performance to MLP.

## Thursday: Regularization & Best Practices
**Topics:**
- Dropout, batch normalization, data augmentation.

**Notebook Tasks:**
- Add dropout & batch norm.
- Plot training curves, observe improvements.

## Friday: Mini-Project – CNN Showcase
- Build a short pipeline from data loading → CNN training → experiment logging → evaluation.

**Industry Context:**
- Where CNNs are used (object detection in self-driving, face recognition, etc.).

## Weekend
**Review:**
- Confirm your notebooks run cleanly end-to-end.

**ADHD Tip:**
- If you feel overwhelmed, break tasks into smaller code cells (one function per cell).